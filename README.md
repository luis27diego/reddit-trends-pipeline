# ğŸ”¥ Reddit Trends Pipeline

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://python.org)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.5-orange?logo=apachespark)](https://spark.apache.org)
[![Prefect](https://img.shields.io/badge/Prefect-3.x-purple?logo=prefect)](https://prefect.io)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker)](https://docker.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue?logo=postgresql)](https://postgresql.org)

Pipeline ETL completo para anÃ¡lisis de tendencias del dataset de Reddit sobre Cambio ClimÃ¡tico. Procesa millones de comentarios usando **Apache Spark** distribuido, orquestado con **Prefect**, almacenado en **MinIO** y visualizado con **Metabase** y **Power BI**.

---

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [Flujo del Pipeline](#-flujo-del-pipeline)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Servicios y Puertos](#-servicios-y-puertos)
- [AnÃ¡lisis Disponibles](#-anÃ¡lisis-disponibles)

---

## âœ¨ CaracterÃ­sticas

- ğŸ“¥ **Ingesta automatizada** desde Kaggle API
- âš¡ **Procesamiento distribuido** con Apache Spark (Master + 2 Workers)
- ğŸ—„ï¸ **Almacenamiento S3-compatible** con MinIO
- ğŸ”„ **OrquestaciÃ³n de flujos** con Prefect 3.x
- ğŸ“Š **MÃºltiples anÃ¡lisis**: temporal, sentimiento, engagement, texto
- ğŸ¯ **API REST** con FastAPI
- ğŸ“ˆ **Dashboards BI** con Metabase y Power BI
- ğŸ³ **Containerizado** con Docker Compose

---

## ğŸ—ï¸ Arquitectura

### Diagrama C4 - Nivel de Contenedores

```mermaid
flowchart TB
    subgraph External["ğŸŒ Fuentes Externas"]
        KG[("ğŸ“¦ Kaggle<br/>Reddit Dataset")]
    end

    subgraph Docker["ğŸ³ Docker Compose"]
        subgraph Orchestration["âš¡ OrquestaciÃ³n"]
            PS["Prefect Server<br/>:4200"]
            PW["Prefect Worker"]
        end

        subgraph Spark["ğŸ”¥ Spark Cluster"]
            SM["Spark Master<br/>:18080"]
            SW1["Worker 1"]
            SW2["Worker 2"]
        end

        subgraph Storage["ğŸ’¾ Storage"]
            MIO[("MinIO<br/>:9000/:9001")]
            PG[("PostgreSQL<br/>:5432")]
        end

        subgraph Presentation["ğŸ“Š PresentaciÃ³n"]
            API["FastAPI<br/>:8000"]
            MB["PowerBI"]
        end
    end


    KG -->|"1. Descarga"| PW
    PS -->|"Orquesta"| PW
    PW -->|"2. Upload raw/"| MIO
    PW -->|"3. Submit Job"| SM
    SM --> SW1 & SW2
    SW1 & SW2 -->|"4. Lee/Escribe"| MIO
    PW -->|"5. Carga analytics"| PG
    API -->|"Query"| PG
    MB -->|"Query"| PG


    %% === PALETA PASTEL NUEVA ===
    style External fill:#F7C6C7,stroke:#F28B90,color:#5A2A2C,stroke-width:2px
    style Docker fill:#D8C8FF,stroke:#B399FF,color:#3A2A5A,stroke-width:2px
    style Orchestration fill:#FFF3B0,stroke:#FFE066,color:#5A4F1A,stroke-width:2px
    style Spark fill:#FFDAC1,stroke:#FFB899,color:#5A392A,stroke-width:2px
    style Storage fill:#C8F7DC,stroke:#93E9B9,color:#1D3D2B,stroke-width:2px
    style Presentation fill:#C7EFFF,stroke:#9AD7FF,color:#1A3C50,stroke-width:2px
```

---

## ğŸ”„ Flujo del Pipeline

### Pipeline ETL Completo

![diagrama](docs/codigo2.drawio.svg)

### Diagrama de Secuencia

```mermaid
%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
Â  Â  autonumber
Â  Â  participant K as Kaggle
Â  Â  participant PW as Prefect Worker
Â  Â  participant MI as MinIO
Â  Â  participant SP as Spark Cluster
Â  Â  participant PG as PostgreSQL
Â  Â  participant BI as PoweBI/API

Â  Â  rect rgb(46, 204, 113, 0.1)
Â  Â  Â  Â  Note over PW,MI: FLUJO 1: INGESTA
Â  Â  Â  Â  PW->>K: download_dataset()
Â  Â  Â  Â  K-->>PW: CSV (raw data)
Â  Â  Â  Â  PW->>MI: upload_file() â†’ raw/
Â  Â  end

Â  Â  rect rgb(241, 196, 15, 0.1)
Â  Â  Â  Â  Note over PW,SP: FLUJO 2: PROCESAMIENTO
Â  Â  Â  Â  PW->>PW: run_deployment("procesamiento")
Â  Â  Â  Â  PW->>SP: create_spark_session()
Â  Â  Â  Â  SP->>MI: leer_csv_optimizado()
Â  Â  Â  Â  MI-->>SP: DataFrame
Â  Â  Â  Â  SP->>SP: AnÃ¡lisis (trends, sentiment, etc.)
Â  Â  Â  Â  SP->>MI: guardar_resultado() â†’ analytics/
Â  Â  end

Â  Â  rect rgb(52, 152, 219, 0.1)
Â  Â  Â  Â  Note over PW,PG: FLUJO 3: CARGA
Â  Â  Â  Â  PW->>PW: run_deployment("carga_bd")
Â  Â  Â  Â  PW->>MI: Lee resultados
Â  Â  Â  Â  MI-->>PW: CSVs procesados
Â  Â  Â  Â  PW->>PG: cargar_resultados_a_db()
Â  Â  end

Â  Â  rect rgb(231, 76, 60, 0.1)
Â  Â  Â  Â  Note over PG,BI: CONSULTA
Â  Â  Â  Â  BI->>PG: SELECT queries
Â  Â  Â  Â  PG-->>BI: Analytics data
Â  Â  end
```

---

## ğŸ“¦ Requisitos

- **Docker** >= 24.0
- **Docker Compose** >= 2.20
- **Kaggle API Key** (para descargar datasets)
- **16GB RAM** mÃ­nimo recomendado (Spark + MinIO + Postgres)

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/reddit-trends-pipeline.git
cd reddit-trends-pipeline
```

### 2. Configurar variables de entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# MinIO
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_ENDPOINT=http://minio:9000
MINIO_BUCKET=reddit-data

# PostgreSQL
POSTGRES_USER=prefect
POSTGRES_PASSWORD=prefect123
POSTGRES_DB=prefect_db
POSTGRES_HOST=postgres 

# Spark
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g
SPARK_MASTER_URL=spark://spark-master:7077

# Prefect
PREFECT_API_URL=http://prefect-server:4200/api
PREFECT_UI_API_URL=http://localhost:4200/api
```

### 3. Configurar Kaggle API

Colocar tu `kaggle.json` en `~/.kaggle/` o configurar variables de entorno:

```bash
export KAGGLE_USERNAME=tu_usuario
export KAGGLE_KEY=tu_api_key
```

### 4. Levantar los servicios

```bash
docker-compose up -d
```

### 5. Verificar servicios

```bash
docker-compose ps
```

---

## ğŸ’» Uso

### Ejecutar el pipeline completo

```bash
# Acceder al Prefect UI
# http://localhost:4200

# Ejecutar flujo de ingesta (trigger manual o programado)
prefect deployment run "Flujo de Ingesta de Reddit/ingesta-deployment"
```

### Acceder a las interfaces

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| Prefect UI | http://localhost:4200 | Orquestador de flujos |
| Spark Master | http://localhost:18080 | Dashboard del cluster |
| MinIO Console | http://localhost:9001 | AdministraciÃ³n de storage |
| FastAPI Docs | http://localhost:8000/docs | API REST Swagger |
| Metabase | http://localhost:3000 | Dashboards BI |

---

## ğŸ“ Estructura del Proyecto

```
ğŸ“¦ reddit-trends-pipeline/
â”‚
â”œâ”€â”€ ğŸ“‚ flows/                          # Flujos de Prefect
â”‚   â”œâ”€â”€ ğŸ“‚ ingesta/
â”‚   â”‚   â”œâ”€â”€ flujo_ingesta.py           # @flow: Descarga desde Kaggle
â”‚   â”‚   â””â”€â”€ tasks_ingesta.py           # @task: Upload a MinIO
â”‚   â”œâ”€â”€ ğŸ“‚ procesamiento/
â”‚   â”‚   â”œâ”€â”€ flujo_procesamiento_reddit.py  # @flow: Procesamiento Spark
â”‚   â”‚   â””â”€â”€ tasks_procesamiento.py     # @task: AnÃ¡lisis distribuido
â”‚   â””â”€â”€ ğŸ“‚ carga_bd/
â”‚       â”œâ”€â”€ flujo_carga_bd.py          # @flow: ETL a PostgreSQL
â”‚       â””â”€â”€ tasks_carga_bd.py          # @task: Carga de resultados
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ api/                        # FastAPI endpoints
â”‚   â”œâ”€â”€ ğŸ“‚ config/                     # Settings y configuraciÃ³n
â”‚   â”œâ”€â”€ ğŸ“‚ infrastructure/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ database/               # ConexiÃ³n PostgreSQL
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ kaggle/                 # Downloader de datasets
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ spark/                  # Session y operaciones I/O
â”‚   â”‚   â””â”€â”€ ğŸ“‚ storage/                # Cliente MinIO
â”‚   â”œâ”€â”€ ğŸ“‚ services/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ analytics/              # MÃ³dulos de anÃ¡lisis
â”‚   â”‚   â”‚   â”œâ”€â”€ trends.py              # AnÃ¡lisis temporal
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment.py           # AnÃ¡lisis sentimiento
â”‚   â”‚   â”‚   â”œâ”€â”€ engagement.py          # Controversia
â”‚   â”‚   â”‚   â”œâ”€â”€ anomalies.py           # DetecciÃ³n de picos
â”‚   â”‚   â”‚   â”œâ”€â”€ text_analysis.py       # Palabras clave
â”‚   â”‚   â”‚   â””â”€â”€ reporting.py           # Comparativas
â”‚   â”‚   â””â”€â”€ ğŸ“‚ loader/                 # Carga a BD
â”‚   â””â”€â”€ ğŸ“‚ utils/                      # Utilidades
â”‚
â”œâ”€â”€ ğŸ“‚ docker/                         # Dockerfiles
â”‚   â”œâ”€â”€ ğŸ“‚ api/
â”‚   â”œâ”€â”€ ğŸ“‚ base/
â”‚   â”œâ”€â”€ ğŸ“‚ spark/
â”‚   â””â”€â”€ ğŸ“‚ worker/
â”‚
â”œâ”€â”€ ğŸ“‚ sql/                            # Scripts SQL
â”‚   â””â”€â”€ ğŸ“‚ init/                       # InicializaciÃ³n BD
â”‚
â”œâ”€â”€ docker-compose.yaml                # OrquestaciÃ³n de servicios
â”œâ”€â”€ prefect.yaml                       # ConfiguraciÃ³n Prefect
â”œâ”€â”€ tablero.pbix                       # Dashboard Power BI
â””â”€â”€ README.md
```

---

## ğŸŒ Servicios y Puertos

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| **MinIO API** | 9000 | API S3-compatible |
| **MinIO Console** | 9001 | Interfaz web de administraciÃ³n |
| **Spark Master UI** | 18080 | Dashboard del cluster Spark |
| **Spark Worker 1** | 18081 | UI Worker 1 |
| **Spark Worker 2** | 18082 | UI Worker 2 |
| **PostgreSQL** | 5432 | Base de datos |
| **Prefect UI** | 4200 | Orquestador de flujos |
| **FastAPI** | 8000 | REST API |
| **Metabase** | 3000 | BI Dashboards |

---

## ğŸ“Š AnÃ¡lisis Disponibles

El pipeline genera los siguientes anÃ¡lisis sobre los comentarios de Reddit:

### ğŸ• AnÃ¡lisis Temporal
- **Tendencias diarias**: Volumen de comentarios por dÃ­a
- **Patrones horarios**: Actividad por hora del dÃ­a
- **DetecciÃ³n de anomalÃ­as**: Picos inusuales de actividad

### ğŸ’¬ AnÃ¡lisis de Sentimiento
- **DistribuciÃ³n sentiment vs score**: CorrelaciÃ³n entre sentimiento y puntuaciÃ³n
- **Comentarios extremos**: Los mÃ¡s positivos y negativos

### ğŸ“ˆ AnÃ¡lisis de Engagement
- **Controversia por subreddit**: MÃ©tricas de engagement por comunidad

### ğŸ“ AnÃ¡lisis de Texto
- **Palabras clave por sentimiento**: Top palabras asociadas a cada sentimiento

### ğŸ“‹ Reportes Consolidados
- **Comparativa de subreddits**: MÃ©tricas comparativas entre comunidades

---

## ğŸ› ï¸ TecnologÃ­as

| CategorÃ­a | TecnologÃ­a | VersiÃ³n |
|-----------|------------|---------|
| Lenguaje | Python | 3.11 |
| Procesamiento | Apache Spark | 3.5 |
| OrquestaciÃ³n | Prefect | 3.x |
| Storage | MinIO | Latest |
| Base de Datos | PostgreSQL | 15 |
| API | FastAPI | Latest |
| BI | Metabase | Latest |
| BI Desktop | Power BI | - |
| Contenedores | Docker Compose | - |

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¥ Contribuir

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios que te gustarÃ­a hacer.

---

<p align="center">
  Hecho con â¤ï¸ usando Apache Spark, Prefect y Docker
</p>